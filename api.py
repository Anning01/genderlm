# -*- coding: utf-8 -*-
import io
import os
import uuid
from collections import deque
from datetime import datetime
from threading import Lock
from typing import List, Optional

import torch
from PIL import Image
from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from transformers import AutoImageProcessor, AutoModelForImageClassification

from face_detector import FaceDetector

app = FastAPI(
    title="Gender Classification API",
    description="ä½¿ç”¨ Vision Transformer æ¨¡å‹è¿›è¡Œæ€§åˆ«è¯†åˆ«ï¼Œæ”¯æŒäººè„¸æ£€æµ‹å’Œæ‰¹é‡å¤„ç†",
    version="2.0.0"
)

# æ¨¡å‹è·¯å¾„é…ç½®
LOCAL_MODEL_PATH = "./gender-classification-2"
HF_MODEL_NAME = "rizvandwiki/gender-classification-2"

# ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
if os.path.exists(LOCAL_MODEL_PATH):
    print(f"âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {LOCAL_MODEL_PATH}")
    model_path = LOCAL_MODEL_PATH
else:
    print(f"â¬‡ï¸  æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œä» Hugging Face ä¸‹è½½: {HF_MODEL_NAME}")
    model_path = HF_MODEL_NAME

# åŠ è½½æ€§åˆ«è¯†åˆ«æ¨¡å‹
print("ğŸ”„ æ­£åœ¨åŠ è½½æ€§åˆ«è¯†åˆ«æ¨¡å‹...")
processor = AutoImageProcessor.from_pretrained(model_path)
model = AutoModelForImageClassification.from_pretrained(model_path)
print("âœ… æ€§åˆ«è¯†åˆ«æ¨¡å‹åŠ è½½å®Œæˆ!")

# åŠ è½½äººè„¸æ£€æµ‹æ¨¡å‹
print("ğŸ”„ æ­£åœ¨åŠ è½½äººè„¸æ£€æµ‹æ¨¡å‹...")
try:
    # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ (0.4) æé«˜æ£€æµ‹çµæ•åº¦
    face_detector = FaceDetector(det_thresh=0.4)
    print("âœ… äººè„¸æ£€æµ‹æ¨¡å‹åŠ è½½å®Œæˆ!")
    FACE_DETECTION_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸  äººè„¸æ£€æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    print("âš ï¸  å°†ä¸æ”¯æŒäººè„¸æ£€æµ‹åŠŸèƒ½")
    face_detector = None
    FACE_DETECTION_AVAILABLE = False


# é˜Ÿåˆ—ç³»ç»Ÿ
class TaskQueue:
    """ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨"""
    def __init__(self, max_size: int = 1000):
        self.tasks = {}  # task_id -> task_info
        self.pending = deque()  # å¾…å¤„ç†é˜Ÿåˆ—
        self.processing = {}  # æ­£åœ¨å¤„ç†çš„ä»»åŠ¡
        self.completed = {}  # å·²å®Œæˆçš„ä»»åŠ¡ (æœ€å¤šä¿ç•™100ä¸ª)
        self.failed = {}  # å¤±è´¥çš„ä»»åŠ¡ (æœ€å¤šä¿ç•™100ä¸ª)
        self.max_size = max_size
        self.max_history = 100
        self.lock = Lock()

    def add_task(self, task_id: str, files_count: int, use_face_detection: bool = False):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        with self.lock:
            if len(self.tasks) >= self.max_size:
                raise HTTPException(status_code=429, detail="é˜Ÿåˆ—å·²æ»¡ï¼Œè¯·ç¨åé‡è¯•")

            task_info = {
                "task_id": task_id,
                "status": "pending",
                "files_count": files_count,
                "processed_count": 0,
                "results": [],
                "use_face_detection": use_face_detection,
                "created_at": datetime.now().isoformat(),
                "started_at": None,
                "completed_at": None,
                "error": None
            }
            self.tasks[task_id] = task_info
            self.pending.append(task_id)
            return task_info

    def start_task(self, task_id: str):
        """å¼€å§‹å¤„ç†ä»»åŠ¡"""
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id]["status"] = "processing"
                self.tasks[task_id]["started_at"] = datetime.now().isoformat()
                self.processing[task_id] = self.tasks[task_id]
                if task_id in self.pending:
                    self.pending.remove(task_id)

    def update_progress(self, task_id: str, result: dict):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id]["results"].append(result)
                self.tasks[task_id]["processed_count"] += 1

    def complete_task(self, task_id: str):
        """å®Œæˆä»»åŠ¡"""
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id]["status"] = "completed"
                self.tasks[task_id]["completed_at"] = datetime.now().isoformat()
                self.completed[task_id] = self.tasks[task_id]
                if task_id in self.processing:
                    del self.processing[task_id]

                # ä¿ç•™æœ€è¿‘çš„å†å²è®°å½•
                if len(self.completed) > self.max_history:
                    oldest = list(self.completed.keys())[0]
                    del self.completed[oldest]
                    del self.tasks[oldest]

    def fail_task(self, task_id: str, error: str):
        """ä»»åŠ¡å¤±è´¥"""
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id]["status"] = "failed"
                self.tasks[task_id]["error"] = error
                self.tasks[task_id]["completed_at"] = datetime.now().isoformat()
                self.failed[task_id] = self.tasks[task_id]
                if task_id in self.processing:
                    del self.processing[task_id]

                # ä¿ç•™æœ€è¿‘çš„å†å²è®°å½•
                if len(self.failed) > self.max_history:
                    oldest = list(self.failed.keys())[0]
                    del self.failed[oldest]
                    del self.tasks[oldest]

    def get_task(self, task_id: str) -> Optional[dict]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        with self.lock:
            return self.tasks.get(task_id)

    def get_stats(self) -> dict:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return {
                "total_tasks": len(self.tasks),
                "pending": len(self.pending),
                "processing": len(self.processing),
                "completed": len(self.completed),
                "failed": len(self.failed),
                "queue_capacity": self.max_size
            }


# å…¨å±€é˜Ÿåˆ—å®ä¾‹
task_queue = TaskQueue()


def predict_single_image(
    image: Image.Image,
    use_face_detection: bool = False,
    face_scale: float = 1.2
) -> dict:
    """
    é¢„æµ‹å•å¼ å›¾ç‰‡çš„æ€§åˆ«

    Args:
        image: PIL Image å¯¹è±¡
        use_face_detection: æ˜¯å¦ä½¿ç”¨äººè„¸æ£€æµ‹
        face_scale: äººè„¸è£å‰ªçš„ç¼©æ”¾æ¯”ä¾‹

    Returns:
        é¢„æµ‹ç»“æœå­—å…¸
    """
    result = {
        "face_detected": False,
        "face_crop_applied": False,
        "original_size": image.size
    }

    # äººè„¸æ£€æµ‹å’Œè£å‰ª
    if use_face_detection and FACE_DETECTION_AVAILABLE:
        cropped_face = face_detector.detect_and_crop(image, use_bbox=True, scale=face_scale)
        if cropped_face:
            result["face_detected"] = True
            result["face_crop_applied"] = True
            result["cropped_size"] = cropped_face.size
            image = cropped_face
        else:
            result["face_detected"] = False
            result["warning"] = "æœªæ£€æµ‹åˆ°äººè„¸ï¼Œä½¿ç”¨åŸå§‹å›¾ç‰‡"

    # é¢„å¤„ç†
    inputs = processor(images=image, return_tensors="pt")

    # æ¨ç†
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class_id = logits.argmax(-1).item()

    # è·å–é¢„æµ‹ç»“æœ
    label = model.config.id2label[predicted_class_id]
    probabilities = torch.nn.functional.softmax(logits, dim=-1)[0]
    confidence = probabilities[predicted_class_id].item()

    # æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    all_probabilities = {
        model.config.id2label[i]: float(probabilities[i].item())
        for i in range(len(probabilities))
    }

    result.update({
        "gender": label,
        "confidence": round(confidence, 4),
        "probabilities": all_probabilities
    })

    return result


async def process_batch_task(task_id: str, files: List[UploadFile], use_face_detection: bool):
    """åå°å¤„ç†æ‰¹é‡ä»»åŠ¡"""
    try:
        task_queue.start_task(task_id)

        for idx, file in enumerate(files):
            try:
                # è¯»å–å›¾ç‰‡
                contents = await file.read()
                image = Image.open(io.BytesIO(contents)).convert("RGB")

                # é¢„æµ‹
                result = predict_single_image(image, use_face_detection)
                result["filename"] = file.filename
                result["index"] = idx

                # æ›´æ–°è¿›åº¦
                task_queue.update_progress(task_id, result)

            except Exception as e:
                # å•ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶
                error_result = {
                    "filename": file.filename,
                    "index": idx,
                    "error": str(e),
                    "success": False
                }
                task_queue.update_progress(task_id, error_result)

        # å®Œæˆä»»åŠ¡
        task_queue.complete_task(task_id)

    except Exception as e:
        task_queue.fail_task(task_id, str(e))


@app.get("/")
async def root():
    """API æ ¹è·¯å¾„"""
    return {
        "message": "Gender Classification API v2.0",
        "features": {
            "face_detection": FACE_DETECTION_AVAILABLE,
            "batch_processing": True,
            "queue_system": True
        },
        "endpoints": {
            "/predict": "POST - å•å¼ å›¾ç‰‡æ€§åˆ«è¯†åˆ«",
            "/predict/batch": "POST - æ‰¹é‡å›¾ç‰‡æ€§åˆ«è¯†åˆ«",
            "/task/{task_id}": "GET - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€",
            "/queue/stats": "GET - é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯",
            "/health": "GET - å¥åº·æ£€æŸ¥",
            "/docs": "GET - API æ–‡æ¡£"
        }
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    stats = task_queue.get_stats()
    return {
        "status": "healthy",
        "gender_model": "loaded",
        "face_detection": "available" if FACE_DETECTION_AVAILABLE else "unavailable",
        "queue_stats": stats
    }


@app.get("/queue/stats")
async def queue_stats():
    """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
    return task_queue.get_stats()


@app.get("/task/{task_id}")
async def get_task_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    task = task_queue.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return task


@app.post("/predict")
async def predict_gender(
    file: UploadFile = File(...),
    use_face_detection: bool = False,
    face_scale: float = 1.2
):
    """
    å•å¼ å›¾ç‰‡æ€§åˆ«è¯†åˆ«

    å‚æ•°:
        file: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒ JPG, PNG ç­‰æ ¼å¼ï¼‰
        use_face_detection: æ˜¯å¦ä½¿ç”¨äººè„¸æ£€æµ‹å’Œè£å‰ª (é»˜è®¤: False)
        face_scale: äººè„¸è£å‰ªçš„ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤: 1.2)

    è¿”å›:
        JSON æ ¼å¼çš„é¢„æµ‹ç»“æœ
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é¡»æ˜¯å›¾ç‰‡æ ¼å¼")

        # æ£€æŸ¥äººè„¸æ£€æµ‹æ˜¯å¦å¯ç”¨
        if use_face_detection and not FACE_DETECTION_AVAILABLE:
            raise HTTPException(
                status_code=400,
                detail="äººè„¸æ£€æµ‹åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·è®¾ç½® use_face_detection=False"
            )

        # è¯»å–å›¾ç‰‡
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")

        # é¢„æµ‹
        result = predict_single_image(image, use_face_detection, face_scale)
        result["filename"] = file.filename
        result["success"] = True

        return JSONResponse(content=result)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")


@app.post("/predict/batch")
async def predict_batch(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    use_face_detection: bool = False
):
    """
    æ‰¹é‡å›¾ç‰‡æ€§åˆ«è¯†åˆ«

    å‚æ•°:
        files: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
        use_face_detection: æ˜¯å¦ä½¿ç”¨äººè„¸æ£€æµ‹å’Œè£å‰ª (é»˜è®¤: False)

    è¿”å›:
        ä»»åŠ¡IDï¼Œå¯ç”¨äºæŸ¥è¯¢å¤„ç†è¿›åº¦
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        if len(files) == 0:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶")

        if len(files) > 100:
            raise HTTPException(status_code=400, detail="å•æ¬¡æœ€å¤šä¸Šä¼ 100ä¸ªæ–‡ä»¶")

        # æ£€æŸ¥äººè„¸æ£€æµ‹æ˜¯å¦å¯ç”¨
        if use_face_detection and not FACE_DETECTION_AVAILABLE:
            raise HTTPException(
                status_code=400,
                detail="äººè„¸æ£€æµ‹åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·è®¾ç½® use_face_detection=False"
            )

        # åˆ›å»ºä»»åŠ¡
        task_id = str(uuid.uuid4())
        task_queue.add_task(task_id, len(files), use_face_detection)

        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(process_batch_task, task_id, files, use_face_detection)

        return JSONResponse(content={
            "success": True,
            "task_id": task_id,
            "files_count": len(files),
            "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨åå°å¤„ç†",
            "query_url": f"/task/{task_id}"
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
